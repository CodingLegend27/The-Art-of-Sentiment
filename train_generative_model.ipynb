{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.3 64-bit",
   "display_name": "Python 3.8.3 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "4cd7ab41f5fca4b9b44701077e38c5ffd31fe66a6cab21e0214b68d958d0e462"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Notebook zum Trainieren des Neuronalen Netzwerks zur Erzeugung von Musik (ohne Stimmung)\n",
    "Hier wird das Model auf den nicht-gelabelten Datensatz trainiert.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import midi_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speicherort der Checkpoints\n",
    "TRAIN_DIR = \"./trained\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codierung\n",
    "def build_char_to_index(train_vocab, test_vocab):\n",
    "    # Mergen von Train und Test Vocab\n",
    "    vocab = list(train_vocab | test_vocab)\n",
    "    vocab.sort()\n",
    "\n",
    "    vocab_size = len(vocab)\n",
    "\n",
    "    # Dictionary zur Codierung\n",
    "    char_to_index = { char : index for index, char in enumerate(vocab)}\n",
    "\n",
    "    # Speichern der char_to_index Codierung in einer Json-Datei\n",
    "    # damit später midi-Dateien erzeugt werden können\n",
    "    with open(os.path.join(TRAIN_DIR, \"char_to_index.json\"), \"w\") as f:\n",
    "        json.dump(char_to_index, f)\n",
    "    \n",
    "    return char_to_index, vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _split_input(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "def build_dataset(text, char_to_index, seq_length, batch_size, buffer_size=10000):\n",
    "    text_as_int = np.array([char_to_index[c] for c in text.split(\" \")])\n",
    "    char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "\n",
    "    sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "    dataset = sequences.map(_split_input)\n",
    "\n",
    "    dataset = dataset.shuffle(buffer_size).batch(batch_size, drop_remainder=True)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "source": [
    "## Laden des (ungelabelten) Datensatztes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Dazu muss im Ordner 'trained' eine leere Json-Datei mit dem Namen 'char_to_index.json' erstellt werden.\n",
    "\n",
    "_Anmerkung: Bei erstmaligen Laden des Datensatzes müssen alle Midi-Dateien erst codiert werden. Daher benötigt die nächste Zelle bei erstamliger Ausführung ca. 2 Stunden._\n",
    "\n",
    "_Wird die Zelle erneut ausgeführt, dann geht dies deutlich schneller, da nur noch die txt-Dateien geladen werden müssen (ca. 1 Minute)_"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "ed/train/Atelier_Iris_Eternal_Mana_EternalManaThemeWhiteNightImagination.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Mega_Man_X_Capsule.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Legend_Of_Zelda_A_Link_To_the_Past_HyruleCastle.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Warioware_Touched_RocktheMike.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Legend_of_Mana_MakersGallop.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Pokemon_Trading_Card_Game_EliteBattle.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Final_Fantasy_7_AheadOnOurWayRemix.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Ultima_V_Stones.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Mystical_Ninja_Starring_Goemon_Yamato.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Terranigma_Creation.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Monkey_Island_1_-_The_Secret_of_Monkey_Island_-_Intro_by_w3sp.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Adventures_of_Dino_Riki_Level1.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Donkey_Kong_Land_Boss.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Pokemon_Red_Blue_Yellow_Route1.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/StarTropics_UpontheIslands.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Pokemon_Ruby_Sapphire_OceanicMuseum.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Warcraft_III_-_Reign_of_Chaos_-_Blackrock_and_Roll_Human_Theme_1_by_Gori_Fater.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Betrayal_at_Krondor_-_Riddle_Chests_by_w3sp.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Final_Fantasy_9_CleyraDanceEternalHarvest.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/EarthBound_SnowWoodBoardingSchool.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Pokemon_Red_Blue_Yellow_Title_Screen_by_ALF.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/City_Connection_HitACat.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Metal_Slug_Stage_1.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Final_Fantasy_2_RedWings.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Final_Fantasy_Crystal_Chronicles_LeavingtheBodyFreely.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Final_Fantasy_5_Japan_Gilgamesh.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Dragon_Warrior_Overworld_Theme.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Pokemon_Red_Blue_Yellow_Champion_Battle_by_ALF.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Secret_of_Mana_SpiritoftheNight.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Mystical_Ninja_Starring_Goemon_GourmetSoupCastle.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Mario_Kart_Double_Dash_MenuTheme.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Legend_Of_Zelda_Links_Awakening_CreditsDuet.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Final_Fantasy_8_ForceYourWay.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Legend_Of_Zelda_The_Twilight_Princess_MidnasDesperation.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Sonic_the_Hedgehog_2_ChemicalPlantZone.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Donkey_Kong_Country_Bonus_Stage.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Super_Mario_Land_World1.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Legend_Of_Zelda_The_Phantom_Hourglass_WithinaHouse.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Battle_of_Olympus_AtheneSonata.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Mega_Man_2_WoodMansStage.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Sonic_the_Hedgehog_2_EmeraldHillZone.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Warioware_Touched_AshleysTheme.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Bioshock_CohensMasterpiece.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Mirrors_Edge_StillAlive.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Super_Mario_Sunshine_DelfinoPlaza.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Mega_Man_3_DrWilyStage2.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Legend_of_Mana_DreamseedFruit.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Pokemon_Gold_Silver_Route38.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Chrono_Trigger_MagussTheme.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Indiana_Jones_and_the_Last_Crusade_-_Zeppelin_by_w3sp.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Final_Fantasy_7_JENOVA.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Pokemon_Black_White_Bicycle.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Legend_Of_Zelda_A_Link_To_the_Past_Church.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Starcraft_-_Terran_Theme_1_by_Gori_Fater.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Sonic_the_Hedgehog_-_Green_Hill_Zone_by_Gori_Fater.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Fire_Emblem_WindsacrossthePlains.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Kirby_64_FinalBattle.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/BanjoTooie_IsleOHagsCauldronKeep.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Mega_Man_4_DrCossacksCitadelStages34.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Donkey_Kong_Country_Map.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Sonic_the_Hedgehog_-_Star_Light_Zone_by_Gori_Fater.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Legend_Of_Zelda_The_Twilight_Princess_FairyQuestLog.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Super_Mario_RPG_Smithy_Battle.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Donkey_Kong_Country_Bonus_Lose.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Super_Mario_Bros_3_Boss.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Super_Mario_Bros_2_Boss.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Pokemon_Red_Blue_Yellow_SSAnne.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Final_Fantasy_2_Rydia.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Sonic_the_Hedgehog_2_Emerald_Hill_Zone_Two_Players_by_Shazomei.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Baldurs_Gate_SafeinBeregost.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Super_Smash_Bros_Brawl_-_Main_Theme_Accompaniment.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Chrono_Cross_RadicalDreamersUnstolenGem.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Heroes_of_Might_and_Magic_3_MainMenu.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Legend_of_Zelda_Twilight_Princess_-_Trailer_Theme.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Legend_of_Zelda_A_Link_to_the_Past_Sanctuary_by_Gori_Fater.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Conkers_Pocket_Tales_ClawSwamp.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Battle_of_Olympus_OrpheusJourneyArranged.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Legend_of_Zelda_A_Link_to_the_Past_-_Shop_by_Gori_Fater.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Super_Smash_Bros_Melee_HittheTargets.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Mario_Kart_64_KalimariDesert.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Mega_Man_5_Chargeman.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Super_Mario_RPG_HeresSomeWeapons.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Sonic_the_Hedgehog_2_Hill_Top_Zone_by_Shazomei.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Yoshis_Story_TreasureHuntYoshisSong17secondRemix.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Kirby_Super_Star_MineCart.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Final_Fantasy_2_Town.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Mega_Man_7_BurstManHeavier.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Mega_Man_9_GalaxyMansStageGalaxyFantasy.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Zelda_II_The_Adventure_of_Link_Palace.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Super_Mario_Land_World4Chai.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Xenogears_BondsofSeaandFire.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/BanjoTooie_ChillyWillyChilliBilli.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Pokemon_Gold_Silver_Route12.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Sonic_the_Hedgehog_2_MysticCaveZoneTwoplayer.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Silent_Hill_NotTomorrow.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Sonic_the_Hedgehog_2_RaceResults.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Final_Fantasy_8_UltimeciasCastle.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Mike_Tysons_PunchOut_Training.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Legend_Of_Zelda_The_The_Wind_Waker_Ocean.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Crash_Bandicoot_2_NGin.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Ragnarok_Online_ClassicalChristmasinthe13thMonth.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Legend_Of_Zelda_The_The_Wind_Waker_WindTemple.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Super_Smash_Bros_Melee_HyruleTempleFireEmblem.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Final_Fantasy_3_ForeverRachel.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Legend_Of_Zelda_The_OverworldRachmaninoffRemix.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Super_Mario_Galaxy_SpaceJunkGalaxy.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Super_Smash_Bros_Dreamland.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Kirby_Triple_Deluxe_BossBattle.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Final_Fantasy_3_Battle.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Sonic_the_Hedgehog_-_Sound_Effects_by_Gori_Fater.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Chrono_Trigger_SecretoftheForest.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Halo_MainThemeExtendedMawVersion.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Pokemon_Diamond_Pearl_PokemonLeagueDay.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Professor_Layton_and_the_Miracle_Mask_PuzzlesAbound.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Sonic_the_Hedgehog_-_Ending_by_Gori_Fater.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Donkey_Kong_Country_Gang_Plank_Galleon.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Pokemon_Gold_Silver_Route1.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/train/Conkers_Bad_Fur_Day_BatulasTheme.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/BanjoKazooie_MadMonsterMansion.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Super_Mario_World_Overworld2.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Final_Fantasy_7_Overworld.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Legend_Of_Zelda_The_Majoras_Mask_SongOfHealing.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Final_Fantasy_7_DescendentofShinobi.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Legend_Of_Zelda_The_Ocarina_Of_Time_Ganondorf.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Donkey_Kong_Country_2_HotHeadBop.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/BanjoKazooie_Ending.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Legend_Of_Zelda_The_Majoras_Mask_AlienInvasion.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Final_Fantasy_7_TrailofBlood.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Legend_Of_Zelda_The_Ocarina_Of_Time_HyruleCastleTown.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Legend_Of_Zelda_The_Majoras_Mask_ClockTown.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Super_Mario_64_KoopasTheme.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Final_Fantasy_7_AnxiousHeart.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Super_Mario_Bros_Underworld.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Final_Fantasy_7_ElectricdeChocobo.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Legend_Of_Zelda_The_Majoras_Mask_StoneTowerTempleInverted.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Final_Fantasy_7_MarkoftheTraitor.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Legend_Of_Zelda_The_Ocarina_Of_Time_GerudoValley.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Legend_Of_Zelda_The_Ocarina_Of_Time_WindmillHut.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Final_Fantasy_7_ChasingTheBlackCapedMan.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Final_Fantasy_7_LifeStream.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Shadow_of_the_Colossus_TheOpenedWay.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Legend_Of_Zelda_The_Ocarina_Of_Time_GoronCity.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Final_Fantasy_7_WhoAreYou.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Final_Fantasy_7_Continue.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Legend_Of_Zelda_The_Ocarina_Of_Time_InsideJabuJabusBelly.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Final_Fantasy_7_MiningTown.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Final_Fantasy_7_SandyBadlands.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Legend_Of_Zelda_The_Majoras_Mask_CremiasWagonRide.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/BanjoKazooie_FreezeezyPeak.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Goldeneye_Frigate.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Final_Fantasy_7_FortressoftheCondor.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Legend_Of_Zelda_The_Ocarina_of_Time_TempleofTime.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/BanjoKazooie_BubblegloopSwamp.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Legend_Of_Zelda_The_Ocarina_Of_Time_Introduction.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Final_Fantasy_7_WaltzdeChocobo.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Legend_Of_Zelda_The_Majoras_Mask_TheMayorsOffice.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Shadow_of_the_Colossus_TheTaleofthe16Sacrifices.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/BanjoKazooie_ClickClockWood.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Final_Fantasy_7_BattleTheme.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Super_Mario_World_ForestofIllusion.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Final_Fantasy_7_OnThatDay5YearsAgo.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Final_Fantasy_7_HoldingMyThoughtsinMyHeart.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Goldeneye_RunwayX.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Final_Fantasy_7_TheNightmareBegins.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Legend_Of_Zelda_The_Ocarina_Of_Time_SariasSong.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Final_Fantasy_7_Tifa.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/BanjoKazooie_Motzhand.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Tetris_EnterYourName.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Goldeneye_FinishthejobJamesIfyoucan.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Final_Fantasy_7_JudgementDay.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Final_Fantasy_7_AHighwindtakestotheSkies.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/BanjoKazooie_GobisValley.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Super_Mario_Bros_MainTheme.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Super_Mario_World_Castle.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Goldeneye_Dam.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/BanjoKazooie_BoggysIglooHappy.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Final_Fantasy_7_VincentsTheme.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Final_Fantasy_7_CidsTheme.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Super_Mario_64_SelectaFile.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Goldeneye_Statue.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Super_Mario_World_TitleScreen.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Final_Fantasy_7_RufussWelcomingCeremony.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Goldeneye_Runway.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/BanjoKazooie_MumbosMountain.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Final_Fantasy_7_GoldSaucer.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Final_Fantasy_7_CincodeChocobo.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Legend_Of_Zelda_The_Ocarina_Of_Time_OwlsTheme.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Super_Mario_Bros_Underwater.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Goldeneye_Caverns.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Final_Fantasy_7_OppressedPeople.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Legend_Of_Zelda_The_Majoras_Mask_ChaseTheme.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Shadow_of_the_Colossus_TheFarthestLand.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Final_Fantasy_7_GreatWarrior.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/BanjoKazooie_BoggysIglooSad.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Legend_Of_Zelda_The_Majoras_Mask_DekuPalace.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Shadow_of_the_Colossus_Prayer.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Donkey_Kong_Country_2_BayouBoogie.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Final_Fantasy_7_MainTheme.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Goldeneye_FacilityX.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Donkey_Kong_Country_2_JibJig.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Final_Fantasy_7_JenovaAbsolute.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Final_Fantasy_7_CostaDelSol.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Legend_Of_Zelda_The_Ocarina_Of_Time_PreludeofLight.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Legend_Of_Zelda_The_Majoras_Mask_StoneTempleTower.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Final_Fantasy_7_LurkingInTheDarkness.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Final_Fantasy_7_WeaponRaid.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Final_Fantasy_7_ThoseChosenBythePlanet.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Shadow_of_the_Colossus_Memories.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Final_Fantasy_7_AerithsTheme.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Final_Fantasy_7_ItsDifficultToStandOnBothFeetIsntIt.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Tetris_MusicA.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Legend_Of_Zelda_The_Ocarina_Of_Time_KokiriForest.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Donkey_Kong_Country_2_SnakeyChantey.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Super_Mario_World_EndingTheme.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Legend_Of_Zelda_The_Ocarina_Of_Time_LostWoods.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Super_Mario_World_Map.mid\n> Parse MIDI-File: ./data/vgmidi-0.1/unlabelled/test/Super_Mario_World_Overworld.mid\n"
    }
   ],
   "source": [
    "# Datensatz wird codiert geladen\n",
    "# Pfad muss eventuell angepasst werden\n",
    "train_text, train_vocab = midi_loader.load_midi(\"./data/vgmidi-0.1/unlabelled/train/\")\n",
    "\n",
    "# Datensatz zum Testen des NN\n",
    "test_text, test_vocab = midi_loader.load_midi(\"./data/vgmidi-0.1/unlabelled/test/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary zum Konvertiern von Chars zu Integers\n",
    "char_to_index, vocab_size = build_char_to_index(train_vocab, test_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konstanten definieren\n",
    "SEQ_LEN = 256\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstelle Datensatz von den codierten ungelabelten Midi-Dateien\n",
    "train_dataset = build_dataset(train_text, char_to_index, SEQ_LEN, BATCH_SIZE)\n",
    "test_dataset = build_dataset(test_text, char_to_index, SEQ_LEN, BATCH_SIZE)"
   ]
  },
  {
   "source": [
    "## Erstellen des Neuronalen Netzwerks"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konstanten des Models\n",
    "\n",
    "#https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/\n",
    "EMB_DIM = 256\n",
    "\n",
    "# Anzahl der LSTM-Layer\n",
    "N_LSTM_LAYERS = 4\n",
    "\n",
    "# Anzahl der Units in einem LSTM-Layer\n",
    "N_UNTIS = 512\n",
    "\n",
    "# Vocab_size wird beim Erstellen der Codierung zurückgegeben\n",
    "VOCAB_SIZE = vocab_size\n",
    "\n",
    "DROPOUT = 0.05"
   ]
  },
  {
   "source": [
    "### Architektur des Models"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model(batch_size):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Embedding(VOCAB_SIZE, EMB_DIM, batch_input_shape=[batch_size, None]))\n",
    "\n",
    "    # Gegebene Anzahl an LSTM-Layer wird hinzugefügt\n",
    "    for _ in range(N_LSTM_LAYERS):\n",
    "        # model.add(tf.keras.layers.LSTM(N_UNTIS, stateful=True, return_sequences=True, dropout=DROPOUT, recurrent_dropout=DROPOUT))\n",
    "        # TODO Enable Dropout wieder?\n",
    "        model.add(tf.keras.layers.LSTM(N_UNTIS, stateful=True, return_sequences=True))\n",
    "\n",
    "\n",
    "    # Fully-Connected Layer mit Vocab-Size als Dimension\n",
    "    model.add(tf.keras.layers.Dense(vocab_size))\n",
    "\n",
    "    model.summary()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        (64, None, 256)           64512     \n_________________________________________________________________\nlstm (LSTM)                  (64, None, 512)           1574912   \n_________________________________________________________________\nlstm_1 (LSTM)                (64, None, 512)           2099200   \n_________________________________________________________________\nlstm_2 (LSTM)                (64, None, 512)           2099200   \n_________________________________________________________________\nlstm_3 (LSTM)                (64, None, 512)           2099200   \n_________________________________________________________________\ndense (Dense)                (64, None, 252)           129276    \n=================================================================\nTotal params: 8,066,300\nTrainable params: 8,066,300\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "# Build actual model\n",
    "model = build_model(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional können jetzt noch vorhandene Gewichtungen geladen werden\n",
    "# Dazu Kommentierung entfernen und \"<PATH>\" mit dem Pfad der Gewichtungen ersetzen\n",
    "\n",
    "model.load_weights(tf.train.latest_checkpoint(tf.train.latest_checkpoint(\"<PATH>\")))"
   ]
  },
  {
   "source": [
    "### Trainieren des Models"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konstanten\n",
    "\n",
    "LERN_RATE = 0.00001\n",
    "\n",
    "N_EPOCHS = 15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verlust-Funktion\n",
    "def generative_loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kompilieren des Models\n",
    "# mit Adam Opitmizer und eigener Velust-Funktion\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=LERN_RATE)\n",
    "model.compile(optimizer=optimizer, loss=generative_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name der Checkpoints\n",
    "checkpoint_name = os.path.join(TRAIN_DIR, \"unlabelled_checkpoint_{epoch}\")\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_name, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/15\n   6/4686 [..............................] - ETA: 7:46:54 - loss: 5.5289"
    }
   ],
   "source": [
    "# Training wird gestartet\n",
    "history = model.fit(train_dataset, epochs=N_EPOCHS, validation_data=test_dataset, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "source": [
    "## Erzeugen einer Midi-Datei (ohne Gefühlsstimmung)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_18\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_18 (Embedding)     (1, None, 256)            64512     \n_________________________________________________________________\nlstm_72 (LSTM)               (1, None, 512)            1574912   \n_________________________________________________________________\nlstm_73 (LSTM)               (1, None, 512)            2099200   \n_________________________________________________________________\nlstm_74 (LSTM)               (1, None, 512)            2099200   \n_________________________________________________________________\nlstm_75 (LSTM)               (1, None, 512)            2099200   \n_________________________________________________________________\ndense_18 (Dense)             (1, None, 252)            129276    \n=================================================================\nTotal params: 8,066,300\nTrainable params: 8,066,300\nNon-trainable params: 0\n_________________________________________________________________\nModel: \"sequential_18\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_18 (Embedding)     (1, None, 256)            64512     \n_________________________________________________________________\nlstm_72 (LSTM)               (1, None, 512)            1574912   \n_________________________________________________________________\nlstm_73 (LSTM)               (1, None, 512)            2099200   \n_________________________________________________________________\nlstm_74 (LSTM)               (1, None, 512)            2099200   \n_________________________________________________________________\nlstm_75 (LSTM)               (1, None, 512)            2099200   \n_________________________________________________________________\ndense_18 (Dense)             (1, None, 252)            129276    \n=================================================================\nTotal params: 8,066,300\nTrainable params: 8,066,300\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "import midi_generator\n",
    "\n",
    "# neues Model mit Batch-Size=1 wird erstellt\n",
    "generative_model = build_model(1)\n",
    "\n",
    "# vorhandene Gewichte werden geladen\n",
    "generative_model.load_weights(tf.train.latest_checkpoint(TRAIN_DIR))\n",
    "\n",
    "# Input shape anpassen\n",
    "generative_model.build(tf.TensorShape([1, None]))\n",
    "#from tfkerassurgeon.operations import delete_layer, insert_layer\n",
    "#from tensorflow.keras.layers import Input\n",
    "#new_input = Input(shape=[1, 1, N_UNTIS])\n",
    "#generative_model = delete_layer(generative_model, generative_model.layers[0])\n",
    "#generative_model = insert_layer(generative_model, generative_model.layers[0], new_input)\n",
    "\n",
    "\n",
    "# Umkehrung der Codierung: Index zu Char\n",
    "index_to_char = {index : char for char, index in char_to_index.items()}\n",
    "\n",
    "# Midi-Generator wird aufgerufen\n",
    "#midi_generator.generate_midi(model=generative_model, char_to_index=char_to_index, index_to_char=index_to_char, midi_file_name=\"generated_midi_unlabelled.mid\", seq_len=SEQ_LEN)\n",
    "\n",
    "####### SEQ\n",
    "text = midi_generator.generate_midi(model=generative_model, char2idx=char_to_index, idx2char=index_to_char, seq_len=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_loader.write(text, \"midi-test.mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n  t_128 \n t_128 t_128 \n \n t_128 v_108 d_eighth_0 n_40 n_47 w_2 n_35 n_47 w_2 d_eighth_1 n_35 n_47 w_4 n_47 n_47 n_59 w_2 d_eighth_0 n_47 n_47 n_59 w_2 d_eighth_1 n_47 n_52 d_eighth_0 n_59 n_64 w_4 n_64 w_2 d_eighth_1 n_40 n_52 n_64 w_3 d_eighth_0 n_40 w_1 n_52 n_64 w_1 n_40 w_1 n_52 n_64 w_2 n_40 n_52 n_64 w_1 d_eighth_1 n_40 n_52 n_59 n_64 w_3 d_eighth_0 n_52 n_59 n_62 w_2 n_52 n_64 n_71 w_3 n_52 n_64 n_69 w_3 n_52 n_64 n_71 w_2 d_16th_0 n_52 n_64 w_1 n_52 n_59 n_64 w_3 d_eighth_0 n_52 n_62 w_2 d_16th_0 n_50 n_59 w_1 n_52 n_59 w_3 n_52 n_57 n_64 w_2 n_52 n_64 w_3 d_eighth_0 n_52 n_64 w_2 d_quarter_0 n_52 d_eighth_0 n_64 w_2 d_16th_0 n_52 n_64 w_1 n_55 n_64 w_1 n_52 n_64 w_2 d_eighth_0 n_52 n_64 d_16th_0 n_64 w_1 n_64 n_69 w_3 d_quarter_0 n_57 n_64 w_4 n_52 n_64 w_4 n_52 n_57 d_16th_0 n_64 w_4 d_eighth_0 n_57 n_66 w_3 n_57 n_64 w_2 d_quarter_0 n_52 n_64 w_4 d_eighth_0 n_52 n_64 w_4 n_55 n_64 w_4 n_52 n_59 n_67 w_4 n_55 n_62 n_67 w_4 n_50 n_55 n_62 w_4 n_50 n_55 n_62 w_3 n_55 n_62 w_3 d_quarter_0 n_50 n_57 w_4 d_eighth_0 n_52 n_59 n_64 w_2 n_55 n_62 w_2 n_50 n_59 w_2 d_quarter_0 n_50 n_55 n_62 w_6 d_eighth_0 n_50 n_59 w_2 n_55 n_62 w_2 d_quarter_0 n_50 d_eighth_0 n_62 n_67 w_4 n_62 n_66 w_2 d_quarter_0 n_50 d_eighth_0 n_62 n_67 w_4 n_62 n_67 w_2 n_50 n_62 n_67 w_1 n_50 n_62 n_67 w_1 d_eighth_0 n_48 n_62 n_67 w_1 n_55 n_62 n_69 w_1 d_quarter_0 n_48 w_2 d_eighth_0 n_60 n_64 n_67 w_2 d_quarter_0 n_50 d_eighth_0 n_60 n_67 w_2 n_60 n_65 w_2 d_quarter_0 n_45 d_eighth_0 n_60 n_62 w_2 n_60 n_60 n_65 w_1 d_16th_0 n_48 w_1 d_eighth_0 n_48 d_half_0 n_60 n_64 n_69 w_2 d_quarter_0 n_48 w_4 n_48 w_4 d_eighth_0 n_53 n_60 n_64 w_2 n_53 d_quarter_0 n_60 w_2 d_quarter_0 n_48 w_2 d_eighth_0 n_60 n_65 n_69 w_2 n_53 n_60 n_69 w_2 n_48 n_53 n_60 n_65 w_2 n_48 n_60 n_60 n_65 w_4 n_48 n_57 n_62 n_64 w_2 n_48 n_60 n_65 w_4 n_52 n_60 n_65 w_2 n_52 n_57 n_64 w_2 n_48 n_57 n_64 w_4 n_52 n_57 n_60 w_2 n_48 n_57 w_2 n_48 n_57 w_2 n_53 n_60 w_2 n_48 n_57 n_64 w_4 n_48 n_55 n_60 w_4 n_48 n_55 n_59 w_2 n_52 n_60 w_4 n_47 n_55 n_60 w_4 n_48 n_55 w_4 n_48 n_52 n_60 w_6 n_52 n_55 n_64 w_2 n_48 n_60 w_4 n_48 n_55 n_62 w_4 n_48 n_55 n_60 w_4 n_50 n_55 n_60 w_4 n_50 n_55 n_60 w_4 n_50 n_55 n_59 w_4 n_48 n_55 n_59 w_4 n_52 n_59 w_4 n_50 n_52 n_60 w_4 n_52 n_57 w_4 n_52 n_55 n_59 w_2 n_50 n_57 w_4 n_50 n_55 n_62 w_4 n_50 n_57 n_62 w_2 n_50 n_57 n_62 w_2 n_50 n_57 n_64 w_4 n_50 n_55 n_57 w_4 n_53 n_55 w_4 n_50 n_55 n_62 w_6 d_eighth_0 n_50 n_57 w_2 n_52 n_55 w_2 n_52 n_55 w_2 d_quarter_0 n_52 n_55 d_eighth_0 n_64 w_4 n_67 w_2 d_eighth_1 n_52 n_57 d_eighth_0 n_67 w_3 n_64 w_1 d_eighth_1 n_52 n_52 n_62 w_3 n_52 n_52 n_64 w_4 n_48 n_50 n_57 w_4 n_52 n_52 n_60 w_2 n_52 n_57 n_64 w_3 n_48 n_52 n_64 w_3 d_quarter_0 n_52 n_57 n_64 w_6 n_52 n_57 n_64 w_6 n_52 n_60 n_64 w_6 d_eighth_0 n_52 n_59 d_quarter_0 n_64 w_4 d_eighth_0 n_52 n_59 w_2 d_eighth_1 n_52 n_55 n_64 w_4 d_eighth_0 n_52 n_55 n_64 w_2 n_52 n_52 n_59 w_2 n_52 n_52 n_55 n_64 w_3 n_52 n_52 n_59 n_67 w_3 d_eighth_0 n_52 n_55 n_64 n_71 w_1 d_16th_0 n_52 w_1 n_52 n_59 d_eighth_0 n_69 w_2 n_52 n_52 n_64 w_2 n_52 n_52 d_16th_0 n_67 w_2 n_52 n_66 w_2 d_eighth_0 n_50 n_57 n_66 w_2 n_50 n_57 d_16th_0 n_66 w_2 d_eighth_0 n_54 d_quarter_0 n_66 w_2 d_16th_0 n_52 n_54 w_2 d_eighth_0 n_50 n_57 w_2 n_50 n_57 n_66 d_16th_0 n_74 w_1 n_69 n_74 w_1 d_quarter_0 n_54 d_eighth_0 n_66 n_73 w_4 n_66 n_71 n_74 w_4 n_54 n_66 n_71 w_4 n_50 n_54 n_62 n_71 w_4 n_50 n_54 n_66 n_71 w_4 n_54 n_59 n_71 w_4 n_54 n_62 n_69 n_74 w_8 n_54 n_59 n_66 n_71 w_4 n_54 n_59 n_66 n_71 w_8 n_54 n_59 n_67 n_71 w_4 n_54 n_61 n_66 n_71 w_4 n_54 n_59 n_67 n_73 w_8 n_55 n_62 n_66 n_71 w_12 n_50 n_59 n_66 n_71 w_4 n_47 n_55 n_62 n_66 n_71 w_4 n_47 n_59 n_64 n_67 n_71 w_4 n_59 n_62 n_71 w_4 n_59 n_67 n_71 w_2 d_eighth_0 n_67 n_71 n_79 w_4 n_67 n_74 n_79 w_2 d_quarter_0 n_62 n_71 n_74 w_4 d_eighth_0 n_43 d_quarter_0 n_67 n_71 n_74 w_2 n_55 w_4 n_43 w_4 d_eighth_0 n_67 n_72 n_74 w_2 n_67 n_71 n_76 w_2 n_43 w_2 d_quarter_0 n_67 n_71 n_71 n_79 w_4 d_eighth_0 n_43 w_4 d_half_0 n_41 w_4 d_16th_0 n_67 n_72 n_74 n_77 w_1 n_65 n_67 n_72 n_72 n_72 w_1 d_quarter_0 n_67 n_72 n_72 n_74 w_2 d_quarter_0 n_48 w_4 d_half_0 n_36 n_48 w_4 d_quarter_0 n_36 n_48 w_4 n_36 n_50 d_quarter_1 n_60 n_69 n_72 w_4 d_eighth_0 n_43 w_2 d_quarter_0 n_48 n_48 n_60 n_72 w_2 n_48 n_60 n_72 w_4 n_48 n_53 n_60 n_65 n_72 w_4 d_eighth_0 n_36 d_quarter_0 n_72 n_77 w_2 n_48 n_48 n_60 n_60 w_2 n_48 w_2 d_quarter_0 n_48 n_53 d_eighth_0 n_65 n_77 n_77 w_2 d_quarter_0 n_65 n_77 n_84 w_2 n_48 n_53 n_60 w_2 d_eighth_0 n_65 n_79 n_84 w_4 d_quarter_0 n_36 d_eighth_0 n_72 n_77 n_84 w_2 n_72 n_84 n_84 w_2 d_quarter_0 n_53 n_53 n_60 n_65 w_2 d_eighth_0 n_77 n_80 w_2 v_80 n_41 n_53 n_72 n_77 w_2 v_80 n_53 n_53 n_58 n_65 w_2 v_96 n_41 n_53 n_65 n_72 w_4 n_41 n_51 n_53 n_58 w_2 v_112 d_eighth_0 n_41 n_53 w_2 v_80 n_41 n_48 n_53 w_2 n_41 n_55 n_60 n_65 w_4 n_41 n_53 n_65 n_72 w_4 v_104 d_quarter_0 n_41 w_4 v_96 n_41 n_48 n_60 n_65 n_72 w_6 v_80 n_41 w_4 n_41 n_53 n_60 n_60 w_4 v_96 d_eighth_0 n_39 w_2 n_41 v_96 d_quarter_0 n_60 w_2 v_96 d_eighth_0 n_41 n_53 v_96 n_60 w_2 v_112 n_41 n_53 v_112 n_60 w_2 v_96 d_eighth_0 n_41 v_96 n_53 w_2 v_112 n_53 w_2 n_41 v_96 d_half_0 n_58 w_2 v_112 d_16th_0 n_41 w_2 n_53 w_2 v_104 n_53 w_2 v_108 n_53 w_1 n_53 w_1 v_104 d_eighth_0 n_60 w_2 v_108 d_half_0 n_65 w_4 v_100 d_half_0 n_46 w_4 v_100 d_eighth_0 n_58 w_1 v_96 d_16th_0 n_58 w_2 v_104 n_53 w_2 v_96 n_58 w_2 v_104 n_53 v_100 d_quarter_0 n_65 w_2 v_100 d_eighth_0 n_58 w_1 v_96 n_58 w_2 v_96 n_58 w_2 v_100 d_half_0 n_41 v_96 d_eighth_0 n_63 w_1 v_108 d_16th_0 n_60 w_1 v_100 n_53 n_65 w_2 v_104 n_53 w_1\n"
    }
   ],
   "source": [
    "print(text)\n"
   ]
  },
  {
   "source": [
    "## Hinzufügen einer Logistischen Regression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import csv\n",
    "import pickle\n",
    "\n",
    "from midi_generator import preprocess_sentence\n",
    "import graph_plotter\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sentence(model, text, char2idx, layer_idx):\n",
    "    text = preprocess_sentence(text)\n",
    "\n",
    "    # Reset LSTMs hidden and cell states\n",
    "    model.reset_states()\n",
    "\n",
    "    for c in text.split(\" \"):\n",
    "        # Add the batch dimension\n",
    "        try:\n",
    "            input_eval = tf.expand_dims([char2idx[c]], 0)\n",
    "            predictions = model(input_eval)\n",
    "        except KeyError:\n",
    "            if c != \"\":\n",
    "                print(\"Can't process char\", c)\n",
    "\n",
    "    h_state, c_state = model.get_layer(index=layer_idx).states\n",
    "\n",
    "    # remove the batch dimension\n",
    "    #h_state = tf.squeeze(h_state, 0)\n",
    "    c_state = tf.squeeze(c_state, 0)\n",
    "\n",
    "    return tf.math.tanh(c_state).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(datapath, generative_model, char2idx, layer_idx):\n",
    "    xs, ys = [], []\n",
    "\n",
    "    csv_file = open(datapath, \"r\")\n",
    "    data = csv.DictReader(csv_file)\n",
    "\n",
    "    for row in data:\n",
    "        label = int(row[\"label\"])\n",
    "        filepath = row[\"filepath\"]\n",
    "\n",
    "        data_dir = os.path.dirname(datapath)\n",
    "        phrase_path = os.path.join(data_dir, filepath) + \".mid\"\n",
    "        encoded_path = os.path.join(data_dir, filepath) + \".npy\"\n",
    "\n",
    "        # Load midi file as text\n",
    "        if os.path.isfile(encoded_path):\n",
    "            encoding = np.load(encoded_path)\n",
    "        else:\n",
    "            text, vocab = midi_loader.load_midi(phrase_path, transpo_range=1, stretching_range=1)\n",
    "\n",
    "            # Encode midi text using generative lstm\n",
    "            encoding = encode_sentence(generative_model, text, char2idx, layer_idx)\n",
    "\n",
    "            # Save encoding in file to make it faster to load next time\n",
    "            np.save(encoded_path, encoding)\n",
    "\n",
    "        xs.append(encoding)\n",
    "        ys.append(label)\n",
    "\n",
    "    return np.array(xs), np.array(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier_model(train_dataset, test_dataset, C=2**np.arange(-8, 1).astype(np.float), seed=42, penalty=\"l1\"):\n",
    "    trX, trY = train_dataset\n",
    "    teX, teY = test_dataset\n",
    "\n",
    "    scores = []\n",
    "\n",
    "    # Hyper-parameter optimization\n",
    "    for i, c in enumerate(C):\n",
    "        logreg_model = LogisticRegression(C=c, penalty=penalty, random_state=seed+i, solver=\"liblinear\")\n",
    "        logreg_model.fit(trX, trY)\n",
    "\n",
    "        score = logreg_model.score(teX, teY)\n",
    "        scores.append(score)\n",
    "\n",
    "    c = C[np.argmax(scores)]\n",
    "\n",
    "    sent_classfier = LogisticRegression(C=c, penalty=penalty, random_state=seed+len(C), solver=\"liblinear\")\n",
    "    sent_classfier.fit(trX, trY)\n",
    "\n",
    "    score =  sent_classfier.score(teX, teY) * 100.\n",
    "\n",
    "    # Persist sentiment classifier\n",
    "    with open(os.path.join(TRAIN_DIR, \"classifier_ckpt.p\"), \"wb\") as f:\n",
    "        pickle.dump(sent_classfier, f)\n",
    "\n",
    "    # Get activated neurons\n",
    "    sentneuron_ixs = get_activated_neurons(sent_classfier)\n",
    "\n",
    "    # Plot results\n",
    "    graph_plotter.plot_weight_contribs(sent_classfier.coef_)\n",
    "    graph_plotter.plot_logits(trX, trY, sentneuron_ixs)\n",
    "\n",
    "    return sentneuron_ixs, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activated_neurons(sent_classfier):\n",
    "    neurons_not_zero = len(np.argwhere(sent_classfier.coef_))\n",
    "\n",
    "    weights = sent_classfier.coef_.T\n",
    "    weight_penalties = np.squeeze(np.linalg.norm(weights, ord=1, axis=1))\n",
    "\n",
    "    if neurons_not_zero == 1:\n",
    "        neuron_ixs = np.array([np.argmax(weight_penalties)])\n",
    "    elif neurons_not_zero >= np.log(len(weight_penalties)):\n",
    "        neuron_ixs = np.argsort(weight_penalties)[-neurons_not_zero:][::-1]\n",
    "    else:\n",
    "        neuron_ixs = np.argpartition(weight_penalties, -neurons_not_zero)[-neurons_not_zero:]\n",
    "        neuron_ixs = (neuron_ixs[np.argsort(weight_penalties[neuron_ixs])])[::-1]\n",
    "\n",
    "    return neuron_ixs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_9\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_9 (Embedding)      (1, None, 256)            64512     \n_________________________________________________________________\nlstm_36 (LSTM)               (1, None, 512)            1574912   \n_________________________________________________________________\nlstm_37 (LSTM)               (1, None, 512)            2099200   \n_________________________________________________________________\nlstm_38 (LSTM)               (1, None, 512)            2099200   \n_________________________________________________________________\nlstm_39 (LSTM)               (1, None, 512)            2099200   \n_________________________________________________________________\ndense_9 (Dense)              (1, None, 252)            129276    \n=================================================================\nTotal params: 8,066,300\nTrainable params: 8,066,300\nNon-trainable params: 0\n_________________________________________________________________\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.embeddings\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-5.kernel\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-5.bias\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.kernel\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.recurrent_kernel\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.bias\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.cell.kernel\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.cell.recurrent_kernel\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.cell.bias\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.cell.kernel\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.cell.recurrent_kernel\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.cell.bias\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-4.cell.kernel\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-4.cell.recurrent_kernel\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-4.cell.bias\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.embeddings\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-5.kernel\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-5.bias\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.kernel\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.recurrent_kernel\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.bias\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.cell.kernel\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.cell.recurrent_kernel\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.cell.bias\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.cell.kernel\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.cell.recurrent_kernel\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.cell.bias\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-4.cell.kernel\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-4.cell.recurrent_kernel\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-4.cell.bias\nWARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
    }
   ],
   "source": [
    "# Load weights of model\n",
    "generative_model = build_model(1)\n",
    "generative_model.load_weights(tf.train.latest_checkpoint(TRAIN_DIR))\n",
    "generative_model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "source": [
    "_Anmerkung: Auch hier benötigt das erstmalige Laden der Midi-Dateien deutlich mehr Zeit als danach._"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Build dataset from encoded labelled midis\n",
    "train_dataset = build_dataset(\"./data/vgmidi-0.1/labelled/vgmidi_sent_train.csv\", generative_model, char_to_index, 4)\n",
    "test_dataset = build_dataset(\"./data/vgmidi-0.1/labelled/vgmidi_sent_test.csv\", generative_model, char_to_index, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "sentneuron_ixs, score = train_classifier_model(train_dataset, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "> Anzahl der genutzten Neuronen: 3 \n[466 282 147]\nGenauigkeit: 58.76288659793815\n"
    }
   ],
   "source": [
    "print(f\"> Anzahl der genutzten Neuronen: {len(sentneuron_ixs)} \\n{sentneuron_ixs}\")\n",
    "print(f\"Genauigkeit: {score}\")"
   ]
  },
  {
   "source": [
    "## Anpassen der Gefühlsneuronen \n",
    "Die Neuronen werden trainiert, um Musik mit Stimmung erzeugen zu könnnen"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konstanten\n",
    "GEN_MIN = -1\n",
    "GEN_MAX = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutation(individual, mutation_rate):\n",
    "    for i in range(len(individual)):\n",
    "        if np.random.uniform(0, 1) < mutation_rate:\n",
    "            individual[i] = np.random.uniform(GEN_MIN, GEN_MAX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossover(parent_a, parent_b, ind_size):\n",
    "    # durchschnittliches Crossover\n",
    "    return (parent_a + parent_b)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reproduce(mating_pool, new_population_size, ind_size, mutation_rate):\n",
    "    # Neue 'Population' wird erzeugt\n",
    "    new_population = np.zeros((new_population_size, ind_size))\n",
    "\n",
    "    for i in range(new_population_size):\n",
    "        a = np.random.randint(len(mating_pool))\n",
    "        b = np.random.randint(len(mating_pool))\n",
    "\n",
    "        new_population[i] = crossover(mating_pool[a], mating_pool[b], ind_size)\n",
    "\n",
    "    # Mutation von neuen Kindern\n",
    "    np.apply_along_axis(mutation, 1, new_population, mutation_rate)\n",
    "\n",
    "    return new_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roulette_wheel(population, fitness_pop):\n",
    "    \n",
    "    norm_fitness_pop = fitness_pop/np.sum(fitness_pop)\n",
    "\n",
    "    # Zufällige Auswahl\n",
    "    r = np.random.uniform(0, 1)\n",
    "\n",
    "    fitness_so_far = 0\n",
    "    for i in range(len(population)):\n",
    "        fitness_so_far += norm_fitness_pop[i]\n",
    "\n",
    "        if r < fitness_so_far:\n",
    "            return population[i]\n",
    "\n",
    "    return population[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select(population, fitness_pop, mating_pool_size, ind_size, elite_rate):\n",
    "    mating_pool = np.zeros((mating_pool_size, ind_size))\n",
    "\n",
    "    # Apply roulete wheel to select mating_pool_size individuals\n",
    "    for i in range(mating_pool_size):\n",
    "        mating_pool[i] = roulette_wheel(population, fitness_pop)\n",
    "\n",
    "    # Apply elitism\n",
    "    assert elite_rate >= 0 and elite_rate <= 1\n",
    "    elite_size = int(np.ceil(elite_rate * len(population)))\n",
    "    elite_idxs = np.argsort(-fitness_pop)\n",
    "\n",
    "    for i in range(elite_size):\n",
    "        r = np.random.randint(0, mating_pool_size)\n",
    "        mating_pool[r] = elite_idxs[i]\n",
    "\n",
    "    return mating_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_fitness(individual, gen_model, cls_model, char_to_index, index_to_char, layer_index, sentiment, runs=30):\n",
    "    encoding_size = gen_model.layers[layer_index].units\n",
    "    generated_midis = np.zeros((runs, encoding_size))\n",
    "\n",
    "    # Get activated neurons\n",
    "    sentneuron_ixs = get_activated_neurons(cls_model)\n",
    "    assert len(individual) == len(sentneuron_ixs)\n",
    "\n",
    "    # Use individual gens to override model neurons\n",
    "    override = {}\n",
    "    for i, ix in enumerate(sentneuron_ixs):\n",
    "        override[ix] = individual[i]\n",
    "\n",
    "    # Generate pieces and encode them using the cell state of the generative model\n",
    "    for i in range(runs):\n",
    "        midi_text = midi_generator.generate_midi(gen_model, char_to_index, index_to_char, seq_len=64, layer_idx=layer_index, override=override)\n",
    "        generated_midis[i] = encode_sentence(gen_model, midi_text, char_to_index, layer_index)\n",
    "\n",
    "    midis_sentiment = cls_model.predict(generated_midis).clip(min=0)\n",
    "    return 1.0 - np.sum(np.abs(midis_sentiment - sentiment))/runs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(population, gen_model, cls_model, char_to_index, index_to_char, layer_index, sentiment):\n",
    "    fitness = np.zeros((len(population), 1))\n",
    "\n",
    "    for i in range(len(population)):\n",
    "        fitness[i] = calc_fitness(population[i], gen_model, cls_model, char_to_index, index_to_char, layer_index, sentiment)\n",
    "\n",
    "    return fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evolve(pop_size, ind_size, mut_rate, elite_rate, epochs, generative_model, classifier_model, sentiment):\n",
    "    # Create initial population\n",
    "    print(f\"> Erste Population wird gestartet\")\n",
    "    population = np.random.uniform(GEN_MIN, GEN_MAX, (pop_size, ind_size))\n",
    "\n",
    "    # Bewerten der ersten Population\n",
    "    fitness_pop = evaluate(population, generative_model, classifier_model, char_to_index, index_to_char, 4, sentiment)\n",
    "    print(\">> Fitness: \\n\", fitness_pop)\n",
    "\n",
    "    for i in range(epochs):\n",
    "        print(f\"\\n> Epoch {i+1}/{epochs+1} >>\")\n",
    "\n",
    "        # Select individuals via roulette wheel to form a mating pool\n",
    "        mating_pool = select(population, fitness_pop, pop_size, ind_size, elite_rate)\n",
    "\n",
    "        # Reproduce matin pool with crossover and mutation to form new population\n",
    "        population = reproduce(mating_pool, pop_size, ind_size, mut_rate)\n",
    "\n",
    "        # Calculate fitness of each individual of the population\n",
    "        fitness_pop = evaluate(population, generative_model, classifier_model, char_to_index, index_to_char, 4, sentiment)\n",
    "        print(\">> Fitness: \\n\", fitness_pop)\n",
    "\n",
    "    return population, fitness_pop"
   ]
  },
  {
   "source": [
    "## Start der 'Evolution': Anpassen der Neuronen\n",
    "_Jetzt werden die definierten Methoden benutzt, um die Neuronen zu trainieren, die die gewünschte Stimmung erzeugen sollen._"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weitere Konstanten\n",
    "POPULATION_SIZE = 10\n",
    "EVOLVE_EPOCHS = 10\n",
    "\n",
    "MUTATION_RATE = 0.1\n",
    "ELISTM = 0.1"
   ]
  },
  {
   "source": [
    "### Starten der Evolution für positive Stimmung"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENTIMENT = 1\n",
    "NAME = \"positive\"\n",
    "# für negative Gefühlslage -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# falls das Verzeichnis der Codierung nicht mehr vorhanden ist\n",
    "if (not char_to_index):\n",
    "    with open(os.path.join(TRAIN_DIR, \"char_to_index.json\")) as f:\n",
    "        char_to_index = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (not index_to_char):\n",
    "    index_to_char = {index : char for char, index in char_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(char_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_16\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_16 (Embedding)     (1, None, 256)            64512     \n_________________________________________________________________\nlstm_64 (LSTM)               (1, None, 512)            1574912   \n_________________________________________________________________\nlstm_65 (LSTM)               (1, None, 512)            2099200   \n_________________________________________________________________\nlstm_66 (LSTM)               (1, None, 512)            2099200   \n_________________________________________________________________\nlstm_67 (LSTM)               (1, None, 512)            2099200   \n_________________________________________________________________\ndense_16 (Dense)             (1, None, 252)            129276    \n=================================================================\nTotal params: 8,066,300\nTrainable params: 8,066,300\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "generative_model_positive = build_model(1)\n",
    "generative_model_positive.load_weights(tf.train.latest_checkpoint(TRAIN_DIR))\n",
    "generative_model_positive.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "LogisticRegression(C=0.015625, penalty='l1', random_state=51,\n                   solver='liblinear')\n"
    }
   ],
   "source": [
    "# Laden des Klassifizierungsmodels\n",
    "with open(os.path.join(TRAIN_DIR, \"classifier_ckpt.p\"), \"rb\") as f:\n",
    "    classifier_model_positive = pickle.load(f)\n",
    "\n",
    "print(classifier_model_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentneuron_ixs = get_activated_neurons(classifier_model_positive)\n",
    "index_size = len(sentneuron_ixs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": ">> Fitness: \n [[1.        ]\n [0.86666667]\n [0.96666667]\n [1.        ]\n [0.86666667]\n [0.96666667]\n [0.9       ]\n [0.86666667]\n [1.        ]\n [0.9       ]]\n> Epoch 0 >>\n>> Fitness: \n [[0.86666667]\n [0.86666667]\n [0.96666667]\n [0.93333333]\n [0.86666667]\n [0.96666667]\n [0.93333333]\n [0.83333333]\n [0.76666667]\n [0.93333333]]\n> Epoch 1 >>\n>> Fitness: \n [[0.86666667]\n [0.93333333]\n [0.9       ]\n [0.93333333]\n [0.96666667]\n [0.83333333]\n [0.93333333]\n [0.83333333]\n [0.96666667]\n [0.96666667]]\n> Epoch 2 >>\n>> Fitness: \n [[0.93333333]\n [0.86666667]\n [0.9       ]\n [0.9       ]\n [0.86666667]\n [0.86666667]\n [0.9       ]\n [0.9       ]\n [0.93333333]\n [0.83333333]]\n> Epoch 3 >>\n>> Fitness: \n [[0.73333333]\n [0.86666667]\n [0.86666667]\n [0.83333333]\n [0.93333333]\n [0.93333333]\n [0.93333333]\n [0.83333333]\n [0.96666667]\n [0.8       ]]\n> Epoch 4 >>\n>> Fitness: \n [[0.9       ]\n [0.83333333]\n [0.9       ]\n [0.86666667]\n [0.76666667]\n [0.9       ]\n [0.76666667]\n [0.93333333]\n [0.83333333]\n [0.93333333]]\n> Epoch 5 >>\n>> Fitness: \n [[0.86666667]\n [0.86666667]\n [0.83333333]\n [0.83333333]\n [0.86666667]\n [0.93333333]\n [0.96666667]\n [0.86666667]\n [0.86666667]\n [0.93333333]]\n> Epoch 6 >>\n>> Fitness: \n [[0.9       ]\n [0.9       ]\n [0.86666667]\n [0.86666667]\n [0.93333333]\n [0.93333333]\n [0.8       ]\n [0.93333333]\n [0.76666667]\n [0.93333333]]\n> Epoch 7 >>\n>> Fitness: \n [[0.86666667]\n [0.96666667]\n [1.        ]\n [0.96666667]\n [0.9       ]\n [0.9       ]\n [0.93333333]\n [0.93333333]\n [0.9       ]\n [0.93333333]]\n> Epoch 8 >>\n>> Fitness: \n [[0.83333333]\n [0.83333333]\n [0.96666667]\n [0.96666667]\n [0.86666667]\n [0.9       ]\n [0.9       ]\n [0.86666667]\n [0.8       ]\n [0.86666667]]\n> Epoch 9 >>\n>> Fitness: \n [[0.9       ]\n [0.9       ]\n [0.96666667]\n [0.9       ]\n [0.9       ]\n [0.73333333]\n [0.83333333]\n [0.86666667]\n [0.9       ]\n [0.8       ]]\n"
    }
   ],
   "source": [
    "population_positive, fitness_pop_positive = evolve(POPULATION_SIZE, index_size, MUTATION_RATE, ELISTM, EVOLVE_EPOCHS, generative_model_positive, classifier_model_positive, sentiment=SENTIMENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get bestes Individuum\n",
    "best_index_positive = np.argmax(fitness_pop_positive)\n",
    "best_individual_positive = population_positive[best_index_positive]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use best individual gens to create a dictionary with cell values\n",
    "neurons_positive = {}\n",
    "for i, ix in enumerate(sentneuron_ixs):\n",
    "    neurons_positive[str(ix)] = best_individual_positive[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'466': -0.7949991649771533, '282': -0.0816157120330953, '147': -0.23277896665297285}\n"
    }
   ],
   "source": [
    "print(neurons_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# speichern der positiven Neuronen\n",
    "with open(os.path.join(TRAIN_DIR, \"neurons_\"+NAME+\".json\"), \"w\") as f:\n",
    "    json.dump(neurons, f)"
   ]
  },
  {
   "source": [
    "### Starten der Evolution für negative Gefühlslage"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENTIMENT = -1\n",
    "NAME = \"negative\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_20\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_20 (Embedding)     (1, None, 256)            64512     \n_________________________________________________________________\nlstm_80 (LSTM)               (1, None, 512)            1574912   \n_________________________________________________________________\nlstm_81 (LSTM)               (1, None, 512)            2099200   \n_________________________________________________________________\nlstm_82 (LSTM)               (1, None, 512)            2099200   \n_________________________________________________________________\nlstm_83 (LSTM)               (1, None, 512)            2099200   \n_________________________________________________________________\ndense_20 (Dense)             (1, None, 252)            129276    \n=================================================================\nTotal params: 8,066,300\nTrainable params: 8,066,300\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "generative_model_negative = build_model(1)\n",
    "generative_model_negative.load_weights(tf.train.latest_checkpoint(TRAIN_DIR))\n",
    "generative_model_negative.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "LogisticRegression(C=0.015625, penalty='l1', random_state=51,\n                   solver='liblinear')\n"
    }
   ],
   "source": [
    "# Laden des Klassifizierungsmodels\n",
    "with open(os.path.join(TRAIN_DIR, \"classifier_ckpt.p\"), \"rb\") as f:\n",
    "    classifier_model_negative = pickle.load(f)\n",
    "\n",
    "print(classifier_model_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentneuron_ixs = get_activated_neurons(classifier_model_negative)\n",
    "index_size = len(sentneuron_ixs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "> Erste Population wird gestartet\n>> Fitness: \n [[-0.93333333]\n [-0.9       ]\n [-0.9       ]\n [-0.93333333]\n [-0.86666667]\n [-0.76666667]\n [-0.8       ]\n [-0.96666667]\n [-0.93333333]\n [-0.86666667]]\n> Epoch 0/10 >>\n>> Fitness: \n [[-0.83333333]\n [-0.83333333]\n [-0.86666667]\n [-0.83333333]\n [-0.86666667]\n [-0.96666667]\n [-0.9       ]\n [-0.93333333]\n [-0.83333333]\n [-0.83333333]]\n> Epoch 1/10 >>\n>> Fitness: \n [[-0.96666667]\n [-0.9       ]\n [-0.86666667]\n [-0.96666667]\n [-0.8       ]\n [-0.9       ]\n [-0.9       ]\n [-0.86666667]\n [-0.93333333]\n [-1.        ]]\n> Epoch 2/10 >>\n>> Fitness: \n [[-0.83333333]\n [-0.9       ]\n [-0.93333333]\n [-0.83333333]\n [-0.83333333]\n [-0.96666667]\n [-0.93333333]\n [-0.93333333]\n [-0.93333333]\n [-0.9       ]]\n> Epoch 3/10 >>\n>> Fitness: \n [[-0.93333333]\n [-0.96666667]\n [-0.86666667]\n [-0.93333333]\n [-1.        ]\n [-0.96666667]\n [-0.93333333]\n [-0.86666667]\n [-0.9       ]\n [-0.9       ]]\n> Epoch 4/10 >>\n>> Fitness: \n [[-0.86666667]\n [-0.93333333]\n [-0.93333333]\n [-1.        ]\n [-0.9       ]\n [-0.96666667]\n [-0.93333333]\n [-0.86666667]\n [-0.86666667]\n [-0.93333333]]\n> Epoch 5/10 >>\n>> Fitness: \n [[-0.93333333]\n [-0.9       ]\n [-0.96666667]\n [-0.86666667]\n [-0.9       ]\n [-0.96666667]\n [-0.9       ]\n [-0.9       ]\n [-0.86666667]\n [-0.83333333]]\n> Epoch 6/10 >>\n>> Fitness: \n [[-0.96666667]\n [-0.9       ]\n [-0.83333333]\n [-0.9       ]\n [-0.93333333]\n [-0.83333333]\n [-0.86666667]\n [-0.9       ]\n [-0.86666667]\n [-0.93333333]]\n> Epoch 7/10 >>\n>> Fitness: \n [[-0.93333333]\n [-0.86666667]\n [-0.93333333]\n [-0.96666667]\n [-0.96666667]\n [-0.86666667]\n [-0.86666667]\n [-0.93333333]\n [-0.86666667]\n [-0.9       ]]\n> Epoch 8/10 >>\n>> Fitness: \n [[-0.83333333]\n [-0.93333333]\n [-0.86666667]\n [-0.9       ]\n [-0.9       ]\n [-0.9       ]\n [-0.96666667]\n [-0.86666667]\n [-0.8       ]\n [-0.9       ]]\n> Epoch 9/10 >>\n>> Fitness: \n [[-0.8       ]\n [-0.83333333]\n [-0.86666667]\n [-0.83333333]\n [-0.9       ]\n [-0.96666667]\n [-0.86666667]\n [-0.8       ]\n [-0.9       ]\n [-0.9       ]]\n"
    }
   ],
   "source": [
    "population_negative, fitness_pop_negative = evolve(POPULATION_SIZE, index_size, MUTATION_RATE, ELISTM, EVOLVE_EPOCHS, generative_model_negative, classifier_model_negative, sentiment=SENTIMENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get bestes Individuum\n",
    "best_index_negative = np.argmax(fitness_pop_negative)\n",
    "best_individual_negative = population_negative[best_index_negative]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use best individual gens to create a dictionary with cell values\n",
    "neurons_negative = {}\n",
    "for i, ix in enumerate(sentneuron_ixs):\n",
    "    neurons_negative[str(ix)] = best_individual_negative[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'466': 0.15586915277840535, '282': 0.40943974529414623, '147': 0.08178910856027838}\n"
    }
   ],
   "source": [
    "print(neurons_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# speichern der positiven Neuronen\n",
    "with open(os.path.join(TRAIN_DIR, \"neurons_\"+NAME+\".json\"), \"w\") as f:\n",
    "    json.dump(neurons, f)"
   ]
  },
  {
   "source": [
    "## Erzeugen von Musik mit einer Gefühlslage"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konstanten beliebig verändern:\n",
    "\n",
    "# gewünschte Länge des Stücks\n",
    "DESIRED_SEQ_LEN = 512\n",
    "\n",
    "# gewünschte Gefühlslage \n",
    "# für positive: 1; für negative: -1\n",
    "DESIRED_SENTIMENT = -1\n",
    "\n",
    "# Name der Midi-Datei\n",
    "# hier den ersten String verändern, die Dateiendung (\".mid\") aber behalten\n",
    "MIDI_FILE_NAME = \"midi-negative\" + \".mid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DESIRED_SENTIMENT > 0:\n",
    "    name = \"positive\"\n",
    "else: \n",
    "    name = \"negative\"\n",
    "\n",
    "with open(os.path.join(TRAIN_DIR, \"neurons_\"+name+\".json\")) as f:\n",
    "    NEURONS = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_21\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_21 (Embedding)     (1, None, 256)            64512     \n_________________________________________________________________\nlstm_84 (LSTM)               (1, None, 512)            1574912   \n_________________________________________________________________\nlstm_85 (LSTM)               (1, None, 512)            2099200   \n_________________________________________________________________\nlstm_86 (LSTM)               (1, None, 512)            2099200   \n_________________________________________________________________\nlstm_87 (LSTM)               (1, None, 512)            2099200   \n_________________________________________________________________\ndense_21 (Dense)             (1, None, 252)            129276    \n=================================================================\nTotal params: 8,066,300\nTrainable params: 8,066,300\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "final_generative_model = build_model(1)\n",
    "final_generative_model.load_weights(tf.train.latest_checkpoint(TRAIN_DIR))\n",
    "final_generative_model.build(tf.TensorShape([1, None]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "midi_text = midi_generator.generate_midi(final_generative_model, char_to_index, index_to_char, seq_len=512, layer_idx=4, override=NEURONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n  \n \n t_113 t_128 t_128 v_108 d_quarter_0 n_37 n_49 w_4 n_49 w_4 n_37 n_49 n_49 n_56 n_61 w_4 n_37 n_49 n_56 n_64 n_68 n_73 w_4 d_eighth_1 n_44 n_51 n_61 n_63 n_68 n_73 w_4 d_eighth_1 n_39 n_51 n_56 n_63 n_63 n_70 n_75 w_4 n_39 n_51 n_56 n_65 n_70 w_4 n_39 n_53 n_63 n_68 w_4 n_39 n_56 n_68 w_4 n_39 n_51 n_63 n_70 w_4 n_44 n_51 n_56 n_63 n_68 n_75 w_4 n_44 n_56 n_63 n_70 n_73 w_4 d_half_0 n_44 n_51 n_59 n_63 n_68 n_71 w_16 n_44 n_56 n_63 n_66 n_68 n_75 w_8 d_quarter_0 n_39 n_49 n_59 n_63 n_68 n_70 w_4 d_half_0 n_39 n_51 n_56 n_61 n_63 n_70 w_8 d_eighth_0 n_39 n_51 n_61 n_68 w_2 d_quarter_0 n_42 n_54 n_61 n_68 n_73 w_6 n_42 n_54 n_61 n_70 w_4 d_quarter_0 n_41 n_53 n_61 n_68 n_73 w_4 d_eighth_0 n_41 n_53 n_53 n_60 n_68 n_72 w_4 n_42 n_49 n_61 n_65 n_73 w_4 d_quarter_0 n_42 n_54 n_66 n_70 n_73 w_6 n_42 n_54 n_58 n_66 n_70 n_75 w_8 d_quarter_0 n_41 n_54 n_58 n_65 n_70 n_73 w_4 n_41 n_53 n_61 n_68 n_73 n_73 w_6 n_41 n_56 n_65 n_70 n_72 n_77 w_4 n_41 n_49 n_56 n_65 n_68 n_72 n_77 w_2 n_41 n_56 n_70 n_73 n_77 w_2 n_42 n_53 n_70 n_73 n_73 w_2 n_41 n_53 n_68 n_72 n_77 n_77 w_2 n_42 n_53 n_70 n_73 n_77 w_2 n_41 n_72 n_77 w_2 n_53 n_72 n_75 n_82 w_2 n_41 n_53 n_70 n_75 n_77 n_77 w_1 d_16th_0 n_41 w_1 n_41 w_1 n_41 n_53 n_72 n_72 n_80 w_2 n_41 n_48 n_72 n_77 n_84 w_2 n_41 n_53 n_72 n_79 n_89 w_2 n_36 n_53 n_72 n_79 n_84 w_1 n_41 w_1 n_53 n_72 n_79 n_89 w_1 n_36 n_53 n_74 n_84 w_2 n_41 n_53 n_65 n_79 w_1 n_36 n_53 n_67 n_79 w_3 n_41 n_53 n_65 n_77 w_1 d_16th_0 n_36 n_53 w_1 n_41 n_53 w_1 n_41 n_53 d_eighth_0 n_77 w_1 d_16th_0 n_41 n_53 d_eighth_0 n_79 w_1 d_16th_0 n_39 n_53 d_eighth_1 n_77 w_1 d_16th_0 n_41 w_1 n_53 d_half_0 n_82 w_2 d_eighth_0 n_53 w_2 d_16th_0 n_41 n_53 w_1 n_41 n_53 w_1 n_41 n_53 w_1 n_53 d_eighth_0 n_82 w_1 d_16th_0 n_53 n_53 w_1 n_41 n_53 d_half_0 n_84 d_16th_0 n_84 w_1 d_eighth_0 n_41 n_53 d_16th_0 n_84 w_2 n_41 n_53 n_84 w_1 n_41 n_53 n_84 w_1 n_41 n_48 n_84 n_89 w_1 n_53 d_eighth_0 n_84 w_1 d_16th_0 n_53 n_53 w_1 n_53 d_eighth_0 n_82 n_89 w_1 d_16th_0 n_53 w_1 n_53 w_1 n_53 d_eighth_0 n_89 w_1 d_16th_0 n_53 w_1 n_41 w_1 d_eighth_0 n_53 n_60 n_65 n_89 w_1 d_16th_0 n_53 n_60 d_eighth_0 n_84 n_89 w_1 n_53 n_60 n_65 w_1 d_16th_0 n_84 w_1 n_53 d_eighth_0 n_60 n_65 n_84 w_1 d_quarter_0 n_48 d_eighth_0 n_60 n_65 n_84 w_2 n_53 n_65 n_65 n_84 n_89 w_1 d_16th_0 n_53 n_65 n_65 n_77 n_84 n_89 w_1 n_53 n_65 n_72 n_84 n_84 w_1 d_eighth_0 n_53 n_65 n_72 n_82 n_89 w_2 d_16th_0 n_60 n_65 n_72 n_82 w_1 d_eighth_0 n_65 n_72 n_84 w_2 d_16th_0 n_60 d_eighth_0 n_72 n_89 w_1 d_16th_0 n_65 w_1 n_65 n_72 n_84 w_1 d_eighth_0 n_60 n_68 n_77 w_2 n_65 n_68 d_16th_0 n_82 w_1 n_82 n_89 w_2 d_eighth_0 n_65 n_77 w_2 n_65 n_68 n_77 n_84 w_2 d_eighth_1 n_65 d_eighth_0 n_77 n_84 w_2 n_65 n_77 n_84 w_2 n_65 n_70 n_77 w_2 d_16th_0\n"
    }
   ],
   "source": [
    "print(midi_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_loader.write(midi_text, MIDI_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}